---
speaker: Anca Dragan
affiliation: UC Berkeley
website: "http://people.eecs.berkeley.edu/~anca/"
date: 2023-02-17T12:30:00-0000
location: Skilling Auditorium
location-url: "https://campus-map.stanford.edu/?id=04-550&lat=37.42697371527761&lng=-122.17280664808126&zoom=18&srch=undefined"
title: "Robotics algorithms that take people into account"
abstract: "I discovered AI by reading “Artificial Intelligence: A Modern Approach” (AIMA). What drew me in was the concept that you could specify a goal or objective for a robot, and it would be able to figure out on its own how to sequence actions in order to achieve it. In other words, we don’t have to hand-engineer the robot’s behavior — it emerges from optimal decision making. Throughout my career in robotics and AI, it has always felt satisfying when the robot would autonomously generate a strategy that I felt was the right way to solve the task, and it was even better when the optimal solution would take me a bit by surprise. In “Intro to AI” I share with students an example of this, where a mobile robot figures out it can avoid getting stuck in a pit by moving along the edge. In my group’s research, we tackle the problem of enabling robots to coordinate with and assist people: for example, autonomous cars driving among pedestrians and human-driven vehicles, or robot arms helping people with motor impairments (together with UCSF Neurology). And time and time again, what has sparked the most joy for me is when robots figure out their own strategies that lead to good interaction — when, as in the work your very own faculty Dorsa Sadigh did in her PhD, we don’t have to hand-engineer that an autonomous car should inch forward at a 4-way stop to assert its turn. Instead, the behavior emerges from optimal decision making. So for this seminar, I'd like to step back a bit. Rather than going through one particular piece of research, I will take the opportunity to share what I've found the underlying optimal decision making problem formulation is for HRI -- and reflect on how we've set up optimal decision making problems that require the robot to account for the people it is interacting with, along with the surprising strategies that have emerged from that along the way. This has come back full circle for me, as I got to include some of this perspective in the very book that drew me into the field, by editing the robotics chapter for the 4th edition of AIMA."
youtube-code: "TBD"
---
