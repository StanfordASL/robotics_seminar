---
speaker: Sumeet Singh
affiliation: Stanford
website: "https://web.stanford.edu/~ssingh19/"
date: 2018-11-08T11:00:00-0800
location: "300-300"
location-url: "https://campus-map.stanford.edu/?id=01-300&lat=37.4260997716701&lng=-122.1699424168815&zoom=18"
title: Control-Theoretic Regularization for Nonlinear Dynamical Systems Learning
abstract: "When it works, model-based Reinforcement Learning (RL) typically offers major improvements in sample efficiency in comparison to state of the art RL methods such as Policy Gradients that do not explicitly estimate the underlying dynamical system. Yet, all too often, when standard supervised learning is applied to model complex dynamics, the resulting controllers do not perform at par with model-free RL methods in the limit of increasing sample size, due to compounding errors across long time horizons. In this talk, I will present novel algorithmic tools leveraging Lyapunov-based analysis and semi-infinite convex programming to derive a control-theoretic regularizer for dynamics fitting, rooted in the notion of trajectory stabilizability. The resulting semi-supervised algorithm yields dynamics models that jointly balance regression performance and stabilizability, ultimately resulting in generated trajectories for the robot that are notably easier to track. Evaluation on a simulated quadrotor model illustrates the vastly improved trajectory generation and tracking performance over traditional regression techniques, especially in the regime of small demonstration datasets. I will conclude with a brief discussion of some open questions within this field of control-theoretic learning."
---
