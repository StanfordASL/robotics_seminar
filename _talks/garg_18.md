---
speaker: Animesh Garg
affiliation: Stanford University
website: "http://ai.stanford.edu/~garg/"
date: 2018-01-26T11:00:00-0800
location: Jordan Hall 040
location-url: "https://campus-map.stanford.edu/?id=01-420&lat=37.42865133749201&lng=-122.17121865473717&zoom=17"
title: Towards Generalizable Imitation in Robotics
abstract: "Robotics and AI are experiencing radical growth, fueled by innovations in data-driven learning paradigms coupled with novel device design, in applications such as healthcare, manufacturing and service robotics. Data-driven methods such reinforcement learning circumvent hand-tuned feature engineering, albeit lack guarantees and often incur a massive computational expense: training these models frequently takes weeks in addition to months of task-specific data-collection on physical systems. Further such ab initio methods often do not scale to complex sequential tasks. In contrast, biological agents can often learn faster not only through self-supervision but also imitation. My research aims to bridge this gap and enable generalizable imitation for robot autonomy. We need to build systems that can capture semantic task structures that promote sample efficiency and can generalize to new task instances across visual, dynamical or semantic variations. And this involves designing algorithms that unify in reinforcement learning, control theoretic planning, semantic scene & video understanding, and design.

In this talk three aspects of Generalizable Imitation: Task Structure Learning, Policy Generalization, and Robust/Safe Transfer. First, I will how we can move away from hand-designed finite state machines by unsupervised structure learning for complex multi-step sequential tasks. I will then present a method for generalization across task semantics with a single example with unseen task structure, topology or length. Then I will discuss techniques for robust policy learning to handle generalization across unseen dynamics. And lastly, I will revisit task structure learning to build task representations that generalize across visual semantics. I will present a reference resolution algorithm for task-level understanding from videos. The algorithms and techniques introduced are applicable across domains in robotics; in this talk, I will exemplify these ideas through my work on medical and personal robotics."
---
